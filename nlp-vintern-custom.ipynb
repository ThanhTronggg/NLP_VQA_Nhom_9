{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11836642,"sourceType":"datasetVersion","datasetId":7042757}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q underthesea\n!pip install -q rouge-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:01.394372Z","iopub.execute_input":"2025-05-17T03:55:01.394717Z","iopub.status.idle":"2025-05-17T03:55:13.204339Z","shell.execute_reply.started":"2025-05-17T03:55:01.394691Z","shell.execute_reply":"2025-05-17T03:55:13.203524Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.9/20.9 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m657.8/657.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer, ViTModel, ViTImageProcessor\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.optim import AdamW\nfrom torch.cuda.amp import GradScaler, autocast\nimport nltk\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom rouge_score import rouge_scorer\nimport random\nfrom collections import defaultdict\nimport pickle\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nTRAIN_BATCH_SIZE = 4\nVAL_BATCH_SIZE = 1\nMAX_LEN = 100\nEPOCHS = 2\nACCUMULATION_STEPS = 4","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:13.205987Z","iopub.execute_input":"2025-05-17T03:55:13.206322Z","iopub.status.idle":"2025-05-17T03:55:38.950217Z","shell.execute_reply.started":"2025-05-17T03:55:13.206292Z","shell.execute_reply":"2025-05-17T03:55:38.949636Z"}},"outputs":[{"name":"stderr","text":"2025-05-17 03:55:26.506450: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1747454126.694871      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1747454126.749768      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def split_into_tiles(image, tile_size=448):\n    img_width, img_height = image.size\n    tiles = []\n    for y in range(0, img_height, tile_size):\n        for x in range(0, img_width, tile_size):\n            box = (x, y, min(x + tile_size, img_width), min(y + tile_size, img_height))\n            tile = image.crop(box)\n            if tile.size != (tile_size, tile_size):\n                padded_tile = Image.new('RGB', (tile_size, tile_size), (0, 0, 0))\n                padded_tile.paste(tile, (0, 0))\n                tile = padded_tile\n            tiles.append(tile)\n    return tiles","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:38.950912Z","iopub.execute_input":"2025-05-17T03:55:38.951458Z","iopub.status.idle":"2025-05-17T03:55:38.957006Z","shell.execute_reply.started":"2025-05-17T03:55:38.951435Z","shell.execute_reply":"2025-05-17T03:55:38.956330Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def preprocess_images(df, image_processor, vision_encoder, max_tiles=4, cache_dir=\"visual_cache\"):\n    os.makedirs(cache_dir, exist_ok=True)\n    visual_cache = {}\n    grouped = df.groupby('image_path').agg({\n        'question': list,\n        'answer': list,\n        'image_id': 'first',\n        'index': 'first'\n    }).reset_index()\n\n    vision_encoder.eval()\n    with torch.no_grad():\n        for _, row in tqdm(grouped.iterrows(), total=len(grouped), desc=\"Tiền xử lý ảnh\"):\n            image_path = row['image_path']\n            cache_path = os.path.join(cache_dir, f\"{row['image_id']}.pkl\")\n            if os.path.exists(cache_path):\n                continue\n\n            try:\n                image = Image.open(image_path).convert('RGB')\n                tiles = split_into_tiles(image, tile_size=448)[:max_tiles]\n                processed_tiles = [image_processor(tile, return_tensors=\"pt\")['pixel_values'].squeeze(0) for tile in tiles]\n                visual_tokens = torch.stack(processed_tiles).to(device)  # [num_tiles, 3, 448, 448]\n                visual_features = vision_encoder(pixel_values=visual_tokens).last_hidden_state  # [num_tiles, seq_len, 768]\n                visual_features = visual_features.mean(dim=1)  # [num_tiles, 768]\n                \n                # Kiểm tra kích thước\n                assert visual_features.shape == (max_tiles, 768), f\"Kích thước visual_features không đúng: {visual_features.shape}\"\n                \n                visual_cache[image_path] = visual_features.cpu()\n                with open(cache_path, 'wb') as f:\n                    pickle.dump(visual_features.cpu(), f)\n            except Exception as e:\n                print(f\"Lỗi xử lý ảnh {image_path}: {e}\")\n                visual_cache[image_path] = torch.zeros((max_tiles, 768))\n\n    return visual_cache","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:38.958618Z","iopub.execute_input":"2025-05-17T03:55:38.958856Z","iopub.status.idle":"2025-05-17T03:55:38.973804Z","shell.execute_reply.started":"2025-05-17T03:55:38.958838Z","shell.execute_reply":"2025-05-17T03:55:38.973078Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(self, df, tokenizer, cache_dir=\"visual_cache\", max_len=100, max_tiles=4):\n        self.df = df.groupby('image_path').agg({\n            'question': list,\n            'answer': list,\n            'image_id': 'first',\n            'index': 'first'\n        }).reset_index()\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.cache_dir = cache_dir\n        self.max_tiles = max_tiles\n        self.visual_cache = defaultdict(lambda: None)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = row['image_path']\n        questions = row['question']\n        answers = row['answer']\n        image_id = row['image_id']\n\n        if self.visual_cache[image_path] is None:\n            cache_path = os.path.join(self.cache_dir, f\"{image_id}.pkl\")\n            if os.path.exists(cache_path):\n                with open(cache_path, 'rb') as f:\n                    visual_tokens = pickle.load(f)\n                self.visual_cache[image_path] = visual_tokens\n            else:\n                print(f\"Không tìm thấy cache cho ảnh {image_path}\")\n                visual_tokens = torch.zeros((self.max_tiles, 768))\n\n        visual_tokens = self.visual_cache[image_path].to(device)  # [num_tiles, 768]\n\n        idx_qa = random.randint(0, len(questions) - 1)\n        question = questions[idx_qa]\n        answer = answers[idx_qa]\n\n        question_encoding = self.tokenizer(question, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n        answer_encoding = self.tokenizer(answer, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n\n        return {\n            'visual_tokens': visual_tokens,\n            'question_ids': question_encoding['input_ids'].squeeze(),\n            'question_mask': question_encoding['attention_mask'].squeeze(),\n            'answer_ids': answer_encoding['input_ids'].squeeze(),\n            'answer_mask': answer_encoding['attention_mask'].squeeze()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:38.974716Z","iopub.execute_input":"2025-05-17T03:55:38.975327Z","iopub.status.idle":"2025-05-17T03:55:38.992526Z","shell.execute_reply.started":"2025-05-17T03:55:38.975309Z","shell.execute_reply":"2025-05-17T03:55:38.991823Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class Vintern1BModel(nn.Module):\n    def __init__(self, max_tiles=4):\n        super(Vintern1BModel, self).__init__()\n        self.max_tiles = max_tiles\n        self.mlp_projector = nn.Sequential(\n            nn.Linear(768, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, 4096)\n        )\n        self.language_model = AutoModel.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n\n    def forward(self, visual_tokens, question_ids, question_mask, answer_ids=None):\n        batch_size = question_ids.shape[0]\n        # visual_tokens: [batch_size, num_tiles, 768]\n        if visual_tokens.dim() == 2:  # [num_tiles, 768] -> [1, num_tiles, 768]\n            visual_tokens = visual_tokens.unsqueeze(0)\n        if visual_tokens.shape[0] != batch_size:\n            visual_tokens = visual_tokens.repeat(batch_size, 1, 1)\n        \n        projected_features = self.mlp_projector(visual_tokens)  # [batch_size, num_tiles, 4096]\n        inputs_embeds = self.language_model.get_input_embeddings()(question_ids)  # [batch_size, seq_len, 4096]\n        combined_embeds = torch.cat([projected_features.mean(dim=1, keepdim=True), inputs_embeds], dim=1)  # [batch_size, 1 + seq_len, 4096]\n        outputs = self.language_model(inputs_embeds=combined_embeds, attention_mask=question_mask, labels=answer_ids if answer_ids is not None else None)\n        return outputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:38.993343Z","iopub.execute_input":"2025-05-17T03:55:38.993567Z","iopub.status.idle":"2025-05-17T03:55:39.009536Z","shell.execute_reply.started":"2025-05-17T03:55:38.993551Z","shell.execute_reply":"2025-05-17T03:55:39.008934Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/data-nlp-bai-2/df_train.csv\")\ndf_train = df_train.sort_values(by=[\"image_id\"])\ndf_train = df_train.iloc[:10000]\ndf_train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:39.010307Z","iopub.execute_input":"2025-05-17T03:55:39.010559Z","iopub.status.idle":"2025-05-17T03:55:42.622554Z","shell.execute_reply.started":"2025-05-17T03:55:39.010537Z","shell.execute_reply":"2025-05-17T03:55:42.621758Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"         index  image_id                                    image_path  \\\n5430         4         0    /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n130346      14         0    /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n172135      13         0    /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n149545       7         0    /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n213389       5         0    /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n...        ...       ...                                           ...   \n102697  269206       833  /kaggle/input/data-nlp-bai-2/img/img/833.jpg   \n33054   269205       833  /kaggle/input/data-nlp-bai-2/img/img/833.jpg   \n148169  269212       833  /kaggle/input/data-nlp-bai-2/img/img/833.jpg   \n139086  269207       833  /kaggle/input/data-nlp-bai-2/img/img/833.jpg   \n154229  269215       833  /kaggle/input/data-nlp-bai-2/img/img/833.jpg   \n\n                                                 question  \\\n5430            sách này phù_hợp với trình_độ học_vấn nào   \n130346          ấn_phẩm này được xuất_bản bởi tổ_chức nào   \n172135           nhà_xuất_bản nào phát_hành cuốn sách này   \n149545  môn_học được đề_cập đến trong cuốn sách ở ảnh ...   \n213389          đối_tượng độc_giả của cuốn sách này là ai   \n...                                                   ...   \n102697    trang sách kết_thúc bằng câu hỏi gợi_mở điều gì   \n33054   vấn_đề nào được đề_cập ở câu hỏi khép lại tran...   \n148169  việc bán_thân làm nô_lệ được đề_cập ra sao tro...   \n139086  nêu những khó_khăn mà nông_dân thời lê_sơ phải...   \n154229  tài_liệu cho biết người nông_dân thời lê_sơ_tậ...   \n\n                                                   answer  \n5430                   cuốn sách dành cho học_sinh lớp 12  \n130346  cuốn sách được xuất_bản bởi nhà_xuất_bản giáo_...  \n172135  cuốn sách được xuất_bản bởi nhà_xuất_bản giáo_...  \n149545           cuốn sách trong ảnh thuộc bộ_môn_ngữ văn  \n213389                 cuốn sách dành cho học_sinh lớp 12  \n...                                                   ...  \n102697  câu hỏi cuối_cùng của trang sách đặt ra vấn_đề...  \n33054   câu hỏi cuối_cùng của trang sách đặt ra vấn_đề...  \n148169  pháp_luật nhà lê hạn_chế nghiêm_ngặt việc bán ...  \n139086  nông_dân thời lê_sơ phải đối_mặt với nhiều khó...  \n154229  theo tài_liệu nông_dân thời lê_sơ_sống chủ_yếu...  \n\n[10000 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_id</th>\n      <th>image_path</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5430</th>\n      <td>4</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>sách này phù_hợp với trình_độ học_vấn nào</td>\n      <td>cuốn sách dành cho học_sinh lớp 12</td>\n    </tr>\n    <tr>\n      <th>130346</th>\n      <td>14</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>ấn_phẩm này được xuất_bản bởi tổ_chức nào</td>\n      <td>cuốn sách được xuất_bản bởi nhà_xuất_bản giáo_...</td>\n    </tr>\n    <tr>\n      <th>172135</th>\n      <td>13</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>nhà_xuất_bản nào phát_hành cuốn sách này</td>\n      <td>cuốn sách được xuất_bản bởi nhà_xuất_bản giáo_...</td>\n    </tr>\n    <tr>\n      <th>149545</th>\n      <td>7</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>môn_học được đề_cập đến trong cuốn sách ở ảnh ...</td>\n      <td>cuốn sách trong ảnh thuộc bộ_môn_ngữ văn</td>\n    </tr>\n    <tr>\n      <th>213389</th>\n      <td>5</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>đối_tượng độc_giả của cuốn sách này là ai</td>\n      <td>cuốn sách dành cho học_sinh lớp 12</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>102697</th>\n      <td>269206</td>\n      <td>833</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/833.jpg</td>\n      <td>trang sách kết_thúc bằng câu hỏi gợi_mở điều gì</td>\n      <td>câu hỏi cuối_cùng của trang sách đặt ra vấn_đề...</td>\n    </tr>\n    <tr>\n      <th>33054</th>\n      <td>269205</td>\n      <td>833</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/833.jpg</td>\n      <td>vấn_đề nào được đề_cập ở câu hỏi khép lại tran...</td>\n      <td>câu hỏi cuối_cùng của trang sách đặt ra vấn_đề...</td>\n    </tr>\n    <tr>\n      <th>148169</th>\n      <td>269212</td>\n      <td>833</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/833.jpg</td>\n      <td>việc bán_thân làm nô_lệ được đề_cập ra sao tro...</td>\n      <td>pháp_luật nhà lê hạn_chế nghiêm_ngặt việc bán ...</td>\n    </tr>\n    <tr>\n      <th>139086</th>\n      <td>269207</td>\n      <td>833</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/833.jpg</td>\n      <td>nêu những khó_khăn mà nông_dân thời lê_sơ phải...</td>\n      <td>nông_dân thời lê_sơ phải đối_mặt với nhiều khó...</td>\n    </tr>\n    <tr>\n      <th>154229</th>\n      <td>269215</td>\n      <td>833</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/833.jpg</td>\n      <td>tài_liệu cho biết người nông_dân thời lê_sơ_tậ...</td>\n      <td>theo tài_liệu nông_dân thời lê_sơ_sống chủ_yếu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10000 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"df_test = pd.read_csv(\"/kaggle/input/data-nlp-bai-2/df_test.csv\")\ndf_test = df_test.sort_values(by=[\"image_id\"])\ndf_test = df_test.iloc[:100]\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:42.623379Z","iopub.execute_input":"2025-05-17T03:55:42.623663Z","iopub.status.idle":"2025-05-17T03:55:43.636484Z","shell.execute_reply.started":"2025-05-17T03:55:42.623638Z","shell.execute_reply":"2025-05-17T03:55:43.635678Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"        index  image_id                                   image_path  \\\n20950      12         0   /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n25785      11         0   /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n20374       6         0   /kaggle/input/data-nlp-bai-2/img/img/0.jpg   \n24192      22         1   /kaggle/input/data-nlp-bai-2/img/img/1.jpg   \n447        26         1   /kaggle/input/data-nlp-bai-2/img/img/1.jpg   \n...       ...       ...                                          ...   \n32288  107525        27  /kaggle/input/data-nlp-bai-2/img/img/27.jpg   \n42236  113189        28  /kaggle/input/data-nlp-bai-2/img/img/28.jpg   \n1570   113196        28  /kaggle/input/data-nlp-bai-2/img/img/28.jpg   \n46056  113191        28  /kaggle/input/data-nlp-bai-2/img/img/28.jpg   \n25734  118857        29  /kaggle/input/data-nlp-bai-2/img/img/29.jpg   \n\n                                                question  \\\n20950                   cuốn sách do đơn_vị nào xuất_bản   \n25785       đây là lần tái_bản thứ mấy của cuốn sách này   \n20374           cuốn sách trong ảnh thuộc bộ_môn_học nào   \n24192  ví_dụ 2 câu b mô_tả số phức_nào với độ dài bằn...   \n447    câu c của ví_dụ 2 xác_định số phức nào với giá...   \n...                                                  ...   \n32288  giá_trị số trang nằm ở vị_trí góc trên bên trá...   \n42236  bài thơ có sử_dụng những biện_pháp nghệ_thuật nào   \n1570           bài thơ này chứa_đựng ý_nghĩa sâu_sắc nào   \n46056  bài thơ đã vận_dụng những phương_thức biểu_đạt...   \n25734                      ai là người viết đoạn văn này   \n\n                                                  answer  \n20950  cuốn sách được xuất_bản bởi nhà_xuất_bản giáo_...  \n25785                       cuốn sách được in lần thứ ba  \n20374           cuốn sách trong ảnh thuộc bộ_môn_ngữ văn  \n24192  câu b cho biết số phức 2 cosπ isinπ có modun b...  \n447    câu c cho biết số phức_cos π 2 isin π 2 có mod...  \n...                                                  ...  \n32288  số trang được ghi ở góc trái của trang sách là...  \n42236  bài thơ sử_dụng nhiều biện_pháp nghệ_thuật như...  \n1570   thông_qua bài thơ_tác_giả muốn gửi_gắm thông_đ...  \n46056  bài thơ sử_dụng nhiều biện_pháp nghệ_thuật như...  \n25734      tác_giả của đoạn văn là hoài_thanh thanh_tình  \n\n[100 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>image_id</th>\n      <th>image_path</th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20950</th>\n      <td>12</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>cuốn sách do đơn_vị nào xuất_bản</td>\n      <td>cuốn sách được xuất_bản bởi nhà_xuất_bản giáo_...</td>\n    </tr>\n    <tr>\n      <th>25785</th>\n      <td>11</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>đây là lần tái_bản thứ mấy của cuốn sách này</td>\n      <td>cuốn sách được in lần thứ ba</td>\n    </tr>\n    <tr>\n      <th>20374</th>\n      <td>6</td>\n      <td>0</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/0.jpg</td>\n      <td>cuốn sách trong ảnh thuộc bộ_môn_học nào</td>\n      <td>cuốn sách trong ảnh thuộc bộ_môn_ngữ văn</td>\n    </tr>\n    <tr>\n      <th>24192</th>\n      <td>22</td>\n      <td>1</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/1.jpg</td>\n      <td>ví_dụ 2 câu b mô_tả số phức_nào với độ dài bằn...</td>\n      <td>câu b cho biết số phức 2 cosπ isinπ có modun b...</td>\n    </tr>\n    <tr>\n      <th>447</th>\n      <td>26</td>\n      <td>1</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/1.jpg</td>\n      <td>câu c của ví_dụ 2 xác_định số phức nào với giá...</td>\n      <td>câu c cho biết số phức_cos π 2 isin π 2 có mod...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32288</th>\n      <td>107525</td>\n      <td>27</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/27.jpg</td>\n      <td>giá_trị số trang nằm ở vị_trí góc trên bên trá...</td>\n      <td>số trang được ghi ở góc trái của trang sách là...</td>\n    </tr>\n    <tr>\n      <th>42236</th>\n      <td>113189</td>\n      <td>28</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/28.jpg</td>\n      <td>bài thơ có sử_dụng những biện_pháp nghệ_thuật nào</td>\n      <td>bài thơ sử_dụng nhiều biện_pháp nghệ_thuật như...</td>\n    </tr>\n    <tr>\n      <th>1570</th>\n      <td>113196</td>\n      <td>28</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/28.jpg</td>\n      <td>bài thơ này chứa_đựng ý_nghĩa sâu_sắc nào</td>\n      <td>thông_qua bài thơ_tác_giả muốn gửi_gắm thông_đ...</td>\n    </tr>\n    <tr>\n      <th>46056</th>\n      <td>113191</td>\n      <td>28</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/28.jpg</td>\n      <td>bài thơ đã vận_dụng những phương_thức biểu_đạt...</td>\n      <td>bài thơ sử_dụng nhiều biện_pháp nghệ_thuật như...</td>\n    </tr>\n    <tr>\n      <th>25734</th>\n      <td>118857</td>\n      <td>29</td>\n      <td>/kaggle/input/data-nlp-bai-2/img/img/29.jpg</td>\n      <td>ai là người viết đoạn văn này</td>\n      <td>tác_giả của đoạn văn là hoài_thanh thanh_tình</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 5 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Khởi tạo\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\nimage_processor = ViTImageProcessor.from_pretrained(\"OpenGVLab/InternViT-300M-448px\")\nvision_encoder = ViTModel.from_pretrained(\"OpenGVLab/InternViT-300M-448px\").to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:55:43.637375Z","iopub.execute_input":"2025-05-17T03:55:43.637671Z","iopub.status.idle":"2025-05-17T03:56:16.914620Z","shell.execute_reply.started":"2025-05-17T03:55:43.637647Z","shell.execute_reply":"2025-05-17T03:56:16.913812Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.29k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99d35351f5c948248ed3d7c09052b41d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7364357f009a4db7a18f14bdbbee042f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5cce376be90d4d0a9914aa33299c6233"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"617196192a7a4d2d884be7864ee04226"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9125f3fd120c4d4cbb2f81a81bdc9e47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/748 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11891fd8aba049bc9731a445448d0857"}},"metadata":{}},{"name":"stderr","text":"You are using a model of type intern_vit_6b to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/608M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"382d723241964ffaaf6e7654591fa224"}},"metadata":{}},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at OpenGVLab/InternViT-300M-448px and are newly initialized: ['embeddings.cls_token', 'embeddings.patch_embeddings.projection.bias', 'embeddings.patch_embeddings.projection.weight', 'embeddings.position_embeddings', 'encoder.layer.0.attention.attention.key.bias', 'encoder.layer.0.attention.attention.key.weight', 'encoder.layer.0.attention.attention.query.bias', 'encoder.layer.0.attention.attention.query.weight', 'encoder.layer.0.attention.attention.value.bias', 'encoder.layer.0.attention.attention.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.attention.key.bias', 'encoder.layer.1.attention.attention.key.weight', 'encoder.layer.1.attention.attention.query.bias', 'encoder.layer.1.attention.attention.query.weight', 'encoder.layer.1.attention.attention.value.bias', 'encoder.layer.1.attention.attention.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.attention.key.bias', 'encoder.layer.10.attention.attention.key.weight', 'encoder.layer.10.attention.attention.query.bias', 'encoder.layer.10.attention.attention.query.weight', 'encoder.layer.10.attention.attention.value.bias', 'encoder.layer.10.attention.attention.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.attention.key.bias', 'encoder.layer.11.attention.attention.key.weight', 'encoder.layer.11.attention.attention.query.bias', 'encoder.layer.11.attention.attention.query.weight', 'encoder.layer.11.attention.attention.value.bias', 'encoder.layer.11.attention.attention.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.attention.key.bias', 'encoder.layer.12.attention.attention.key.weight', 'encoder.layer.12.attention.attention.query.bias', 'encoder.layer.12.attention.attention.query.weight', 'encoder.layer.12.attention.attention.value.bias', 'encoder.layer.12.attention.attention.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.layernorm_after.bias', 'encoder.layer.12.layernorm_after.weight', 'encoder.layer.12.layernorm_before.bias', 'encoder.layer.12.layernorm_before.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.attention.attention.key.bias', 'encoder.layer.13.attention.attention.key.weight', 'encoder.layer.13.attention.attention.query.bias', 'encoder.layer.13.attention.attention.query.weight', 'encoder.layer.13.attention.attention.value.bias', 'encoder.layer.13.attention.attention.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.layernorm_after.bias', 'encoder.layer.13.layernorm_after.weight', 'encoder.layer.13.layernorm_before.bias', 'encoder.layer.13.layernorm_before.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.attention.key.bias', 'encoder.layer.14.attention.attention.key.weight', 'encoder.layer.14.attention.attention.query.bias', 'encoder.layer.14.attention.attention.query.weight', 'encoder.layer.14.attention.attention.value.bias', 'encoder.layer.14.attention.attention.value.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.layernorm_after.bias', 'encoder.layer.14.layernorm_after.weight', 'encoder.layer.14.layernorm_before.bias', 'encoder.layer.14.layernorm_before.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.attention.attention.key.bias', 'encoder.layer.15.attention.attention.key.weight', 'encoder.layer.15.attention.attention.query.bias', 'encoder.layer.15.attention.attention.query.weight', 'encoder.layer.15.attention.attention.value.bias', 'encoder.layer.15.attention.attention.value.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.layernorm_after.bias', 'encoder.layer.15.layernorm_after.weight', 'encoder.layer.15.layernorm_before.bias', 'encoder.layer.15.layernorm_before.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.attention.key.bias', 'encoder.layer.16.attention.attention.key.weight', 'encoder.layer.16.attention.attention.query.bias', 'encoder.layer.16.attention.attention.query.weight', 'encoder.layer.16.attention.attention.value.bias', 'encoder.layer.16.attention.attention.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.layernorm_after.bias', 'encoder.layer.16.layernorm_after.weight', 'encoder.layer.16.layernorm_before.bias', 'encoder.layer.16.layernorm_before.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.attention.attention.key.bias', 'encoder.layer.17.attention.attention.key.weight', 'encoder.layer.17.attention.attention.query.bias', 'encoder.layer.17.attention.attention.query.weight', 'encoder.layer.17.attention.attention.value.bias', 'encoder.layer.17.attention.attention.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.layernorm_after.bias', 'encoder.layer.17.layernorm_after.weight', 'encoder.layer.17.layernorm_before.bias', 'encoder.layer.17.layernorm_before.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.attention.attention.key.bias', 'encoder.layer.18.attention.attention.key.weight', 'encoder.layer.18.attention.attention.query.bias', 'encoder.layer.18.attention.attention.query.weight', 'encoder.layer.18.attention.attention.value.bias', 'encoder.layer.18.attention.attention.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.layernorm_after.bias', 'encoder.layer.18.layernorm_after.weight', 'encoder.layer.18.layernorm_before.bias', 'encoder.layer.18.layernorm_before.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.attention.attention.key.bias', 'encoder.layer.19.attention.attention.key.weight', 'encoder.layer.19.attention.attention.query.bias', 'encoder.layer.19.attention.attention.query.weight', 'encoder.layer.19.attention.attention.value.bias', 'encoder.layer.19.attention.attention.value.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.layernorm_after.bias', 'encoder.layer.19.layernorm_after.weight', 'encoder.layer.19.layernorm_before.bias', 'encoder.layer.19.layernorm_before.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.attention.attention.key.bias', 'encoder.layer.2.attention.attention.key.weight', 'encoder.layer.2.attention.attention.query.bias', 'encoder.layer.2.attention.attention.query.weight', 'encoder.layer.2.attention.attention.value.bias', 'encoder.layer.2.attention.attention.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.2.layernorm_after.weight', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.attention.attention.key.bias', 'encoder.layer.20.attention.attention.key.weight', 'encoder.layer.20.attention.attention.query.bias', 'encoder.layer.20.attention.attention.query.weight', 'encoder.layer.20.attention.attention.value.bias', 'encoder.layer.20.attention.attention.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.layernorm_after.bias', 'encoder.layer.20.layernorm_after.weight', 'encoder.layer.20.layernorm_before.bias', 'encoder.layer.20.layernorm_before.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.attention.attention.key.bias', 'encoder.layer.21.attention.attention.key.weight', 'encoder.layer.21.attention.attention.query.bias', 'encoder.layer.21.attention.attention.query.weight', 'encoder.layer.21.attention.attention.value.bias', 'encoder.layer.21.attention.attention.value.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.layernorm_after.bias', 'encoder.layer.21.layernorm_after.weight', 'encoder.layer.21.layernorm_before.bias', 'encoder.layer.21.layernorm_before.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.attention.key.bias', 'encoder.layer.22.attention.attention.key.weight', 'encoder.layer.22.attention.attention.query.bias', 'encoder.layer.22.attention.attention.query.weight', 'encoder.layer.22.attention.attention.value.bias', 'encoder.layer.22.attention.attention.value.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.layernorm_after.bias', 'encoder.layer.22.layernorm_after.weight', 'encoder.layer.22.layernorm_before.bias', 'encoder.layer.22.layernorm_before.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.attention.attention.key.bias', 'encoder.layer.23.attention.attention.key.weight', 'encoder.layer.23.attention.attention.query.bias', 'encoder.layer.23.attention.attention.query.weight', 'encoder.layer.23.attention.attention.value.bias', 'encoder.layer.23.attention.attention.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.layernorm_after.bias', 'encoder.layer.23.layernorm_after.weight', 'encoder.layer.23.layernorm_before.bias', 'encoder.layer.23.layernorm_before.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.attention.attention.key.bias', 'encoder.layer.3.attention.attention.key.weight', 'encoder.layer.3.attention.attention.query.bias', 'encoder.layer.3.attention.attention.query.weight', 'encoder.layer.3.attention.attention.value.bias', 'encoder.layer.3.attention.attention.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.attention.key.bias', 'encoder.layer.4.attention.attention.key.weight', 'encoder.layer.4.attention.attention.query.bias', 'encoder.layer.4.attention.attention.query.weight', 'encoder.layer.4.attention.attention.value.bias', 'encoder.layer.4.attention.attention.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.attention.key.bias', 'encoder.layer.5.attention.attention.key.weight', 'encoder.layer.5.attention.attention.query.bias', 'encoder.layer.5.attention.attention.query.weight', 'encoder.layer.5.attention.attention.value.bias', 'encoder.layer.5.attention.attention.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.attention.key.bias', 'encoder.layer.6.attention.attention.key.weight', 'encoder.layer.6.attention.attention.query.bias', 'encoder.layer.6.attention.attention.query.weight', 'encoder.layer.6.attention.attention.value.bias', 'encoder.layer.6.attention.attention.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.attention.key.bias', 'encoder.layer.7.attention.attention.key.weight', 'encoder.layer.7.attention.attention.query.bias', 'encoder.layer.7.attention.attention.query.weight', 'encoder.layer.7.attention.attention.value.bias', 'encoder.layer.7.attention.attention.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.7.layernorm_before.bias', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.attention.key.bias', 'encoder.layer.8.attention.attention.key.weight', 'encoder.layer.8.attention.attention.query.bias', 'encoder.layer.8.attention.attention.query.weight', 'encoder.layer.8.attention.attention.value.bias', 'encoder.layer.8.attention.attention.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.8.layernorm_after.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.attention.key.bias', 'encoder.layer.9.attention.attention.key.weight', 'encoder.layer.9.attention.attention.query.bias', 'encoder.layer.9.attention.attention.query.weight', 'encoder.layer.9.attention.attention.value.bias', 'encoder.layer.9.attention.attention.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'layernorm.bias', 'layernorm.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"visual_cache_train\", ignore_errors=True)\nshutil.rmtree(\"visual_cache_test\", ignore_errors=True)\n\npreprocess_images(df_train, image_processor, vision_encoder, max_tiles=4, cache_dir=\"visual_cache_train\")\npreprocess_images(df_test, image_processor, vision_encoder, max_tiles=4, cache_dir=\"visual_cache_test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T03:56:16.916831Z","iopub.execute_input":"2025-05-17T03:56:16.917059Z","iopub.status.idle":"2025-05-17T04:03:02.731526Z","shell.execute_reply.started":"2025-05-17T03:56:16.917042Z","shell.execute_reply":"2025-05-17T04:03:02.730772Z"}},"outputs":[{"name":"stderr","text":"Tiền xử lý ảnh:   0%|          | 1/834 [00:01<14:50,  1.07s/it]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/0.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\nLỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/1.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   0%|          | 3/834 [00:01<06:35,  2.10it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/10.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   0%|          | 4/834 [00:02<06:33,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/100.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|          | 5/834 [00:02<06:30,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/101.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|          | 6/834 [00:03<06:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/102.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|          | 7/834 [00:03<06:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/103.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|          | 8/834 [00:03<06:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/104.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|          | 9/834 [00:04<06:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/105.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|          | 10/834 [00:04<06:25,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/106.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|▏         | 11/834 [00:05<06:25,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/107.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   1%|▏         | 12/834 [00:05<06:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/108.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 13/834 [00:06<06:24,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/109.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 14/834 [00:06<06:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/11.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 15/834 [00:07<06:23,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/110.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 16/834 [00:07<06:22,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/111.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 17/834 [00:08<06:22,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/112.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 18/834 [00:08<06:21,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/113.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 19/834 [00:09<06:21,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/114.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   2%|▏         | 20/834 [00:09<06:20,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/115.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 21/834 [00:10<06:20,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/116.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 22/834 [00:10<06:19,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/117.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 23/834 [00:10<06:19,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/118.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 24/834 [00:11<06:18,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/119.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 25/834 [00:11<06:18,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/12.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 26/834 [00:12<06:17,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/120.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 27/834 [00:12<06:17,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/121.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 28/834 [00:13<06:16,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/122.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 29/834 [00:13<06:16,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/123.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▎         | 30/834 [00:14<06:16,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/124.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▎         | 31/834 [00:14<06:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/125.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▍         | 32/834 [00:15<06:15,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/126.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▍         | 33/834 [00:15<06:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/127.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▍         | 34/834 [00:16<06:14,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/128.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▍         | 35/834 [00:16<06:14,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/129.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▍         | 36/834 [00:17<06:13,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/13.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   4%|▍         | 37/834 [00:17<06:12,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/130.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▍         | 38/834 [00:17<06:12,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/131.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▍         | 39/834 [00:18<06:14,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/132.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▍         | 40/834 [00:18<06:10,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/133.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▍         | 41/834 [00:19<06:10,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/134.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▌         | 42/834 [00:19<06:10,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/135.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▌         | 43/834 [00:20<06:09,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/136.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▌         | 44/834 [00:20<06:09,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/137.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   5%|▌         | 45/834 [00:21<06:08,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/138.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 46/834 [00:21<06:08,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/139.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 47/834 [00:22<06:08,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/14.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 48/834 [00:22<06:07,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/140.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 49/834 [00:23<06:07,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/141.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 50/834 [00:23<06:06,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/142.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 51/834 [00:24<06:06,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/143.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▌         | 52/834 [00:24<06:05,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/144.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▋         | 53/834 [00:25<06:05,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/145.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   6%|▋         | 54/834 [00:25<06:05,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/146.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 55/834 [00:25<06:04,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/147.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 56/834 [00:26<06:04,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/148.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 57/834 [00:26<06:03,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/149.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 58/834 [00:27<06:02,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/15.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 59/834 [00:27<06:02,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/150.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 60/834 [00:28<06:02,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/151.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 61/834 [00:28<06:01,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/152.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 62/834 [00:29<06:01,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/153.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 63/834 [00:29<06:00,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/154.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 64/834 [00:30<06:00,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/155.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 65/834 [00:30<05:59,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/156.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 66/834 [00:31<05:59,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/157.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 67/834 [00:31<05:58,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/158.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 68/834 [00:32<05:58,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/159.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 69/834 [00:32<05:57,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/16.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   8%|▊         | 70/834 [00:32<05:57,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/160.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▊         | 71/834 [00:33<05:56,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/161.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▊         | 72/834 [00:33<05:56,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/162.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 73/834 [00:34<05:56,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/163.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 74/834 [00:34<05:55,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/164.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 75/834 [00:35<05:55,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/165.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 76/834 [00:35<05:54,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/166.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 77/834 [00:36<05:54,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/167.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 78/834 [00:36<05:53,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/168.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   9%|▉         | 79/834 [00:37<05:53,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/169.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|▉         | 80/834 [00:37<05:52,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/17.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|▉         | 81/834 [00:38<05:52,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/170.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|▉         | 82/834 [00:38<05:51,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/171.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|▉         | 83/834 [00:39<05:51,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/172.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|█         | 84/834 [00:39<05:50,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/173.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|█         | 85/834 [00:39<05:50,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/174.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|█         | 86/834 [00:40<05:49,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/175.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|█         | 87/834 [00:40<05:49,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/176.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█         | 88/834 [00:41<05:48,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/177.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█         | 89/834 [00:41<05:48,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/178.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█         | 90/834 [00:42<05:48,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/179.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█         | 91/834 [00:42<05:47,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/18.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█         | 92/834 [00:43<05:47,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/180.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█         | 93/834 [00:43<05:46,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/181.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█▏        | 94/834 [00:44<05:46,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/182.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  11%|█▏        | 95/834 [00:44<05:45,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/183.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 96/834 [00:45<05:45,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/184.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 97/834 [00:45<05:44,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/185.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 98/834 [00:46<05:44,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/186.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 99/834 [00:46<05:44,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/187.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 100/834 [00:46<05:43,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/188.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 101/834 [00:47<05:42,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/189.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 102/834 [00:47<05:42,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/19.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 103/834 [00:48<05:42,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/190.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  12%|█▏        | 104/834 [00:48<05:41,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/191.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 105/834 [00:49<05:41,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/192.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 106/834 [00:49<05:40,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/193.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 107/834 [00:50<05:39,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/194.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 108/834 [00:50<05:39,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/195.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 109/834 [00:51<05:39,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/196.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 110/834 [00:51<05:38,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/197.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 111/834 [00:52<05:38,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/198.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  13%|█▎        | 112/834 [00:52<05:37,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/199.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▎        | 113/834 [00:53<05:37,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/2.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▎        | 114/834 [00:53<05:37,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/20.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 115/834 [00:54<05:36,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/200.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 116/834 [00:54<05:36,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/201.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 117/834 [00:54<05:35,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/202.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 118/834 [00:55<05:35,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/203.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 119/834 [00:55<05:34,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/204.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 120/834 [00:56<05:34,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/205.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▍        | 121/834 [00:56<05:33,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/206.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▍        | 122/834 [00:57<05:33,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/207.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▍        | 123/834 [00:57<05:32,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/208.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▍        | 124/834 [00:58<05:32,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/209.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▍        | 125/834 [00:58<05:31,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/21.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▌        | 126/834 [00:59<05:31,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/210.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▌        | 127/834 [00:59<05:30,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/211.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▌        | 128/834 [01:00<05:30,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/212.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  15%|█▌        | 129/834 [01:00<05:29,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/213.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▌        | 130/834 [01:01<05:29,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/214.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▌        | 131/834 [01:01<05:28,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/215.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▌        | 132/834 [01:01<05:28,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/216.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▌        | 133/834 [01:02<05:27,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/217.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▌        | 134/834 [01:02<05:27,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/218.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▌        | 135/834 [01:03<05:27,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/219.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▋        | 136/834 [01:03<05:26,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/22.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  16%|█▋        | 137/834 [01:04<05:25,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/220.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 138/834 [01:04<05:25,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/221.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 139/834 [01:05<05:24,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/222.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 140/834 [01:05<05:24,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/223.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 141/834 [01:06<05:24,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/224.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 142/834 [01:06<05:23,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/225.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 143/834 [01:07<05:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/226.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 144/834 [01:07<05:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/227.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 145/834 [01:08<05:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/228.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 146/834 [01:08<05:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/229.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 147/834 [01:08<05:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/23.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 148/834 [01:09<05:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/230.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 149/834 [01:09<05:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/231.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 150/834 [01:10<05:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/232.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 151/834 [01:10<05:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/233.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 152/834 [01:11<05:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/234.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 153/834 [01:11<05:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/235.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  18%|█▊        | 154/834 [01:12<05:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/236.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▊        | 155/834 [01:12<05:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/237.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▊        | 156/834 [01:13<05:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/238.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▉        | 157/834 [01:13<05:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/239.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▉        | 158/834 [01:14<05:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/24.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▉        | 159/834 [01:14<05:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/240.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▉        | 160/834 [01:15<05:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/241.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▉        | 161/834 [01:15<05:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/242.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  19%|█▉        | 162/834 [01:16<05:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/243.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|█▉        | 163/834 [01:16<05:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/244.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|█▉        | 164/834 [01:16<05:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/245.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|█▉        | 165/834 [01:17<05:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/246.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|█▉        | 166/834 [01:17<05:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/247.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|██        | 167/834 [01:18<05:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/248.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|██        | 168/834 [01:18<05:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/249.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|██        | 169/834 [01:19<05:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/25.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  20%|██        | 170/834 [01:19<05:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/250.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 171/834 [01:20<05:12,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/251.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 172/834 [01:20<05:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/252.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 173/834 [01:21<05:11,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/253.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 174/834 [01:21<05:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/254.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 175/834 [01:22<05:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/255.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 176/834 [01:22<05:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/256.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 177/834 [01:23<05:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/257.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██▏       | 178/834 [01:23<05:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/258.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██▏       | 179/834 [01:24<05:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/259.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 180/834 [01:24<05:07,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/26.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 181/834 [01:24<05:07,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/260.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 182/834 [01:25<05:07,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/261.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 183/834 [01:25<05:06,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/262.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 184/834 [01:26<05:06,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/263.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 185/834 [01:26<05:05,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/264.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 186/834 [01:27<05:05,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/265.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  22%|██▏       | 187/834 [01:27<05:04,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/266.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 188/834 [01:28<05:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/267.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 189/834 [01:28<05:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/268.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 190/834 [01:29<05:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/269.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 191/834 [01:29<05:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/27.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 192/834 [01:30<05:02,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/270.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 193/834 [01:30<05:02,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/271.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 194/834 [01:31<05:01,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/272.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  23%|██▎       | 195/834 [01:31<05:01,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/273.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▎       | 196/834 [01:32<05:00,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/274.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▎       | 197/834 [01:32<05:00,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/275.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▎       | 198/834 [01:32<05:00,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/276.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 199/834 [01:33<04:59,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/277.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 200/834 [01:33<04:58,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/278.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 201/834 [01:34<04:57,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/279.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 202/834 [01:34<04:57,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/28.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 203/834 [01:35<04:57,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/280.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 204/834 [01:35<04:56,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/281.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▍       | 205/834 [01:36<04:56,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/282.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▍       | 206/834 [01:36<04:55,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/283.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▍       | 207/834 [01:37<04:55,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/284.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▍       | 208/834 [01:37<04:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/285.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▌       | 209/834 [01:38<04:54,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/286.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▌       | 210/834 [01:38<04:53,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/287.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▌       | 211/834 [01:39<04:53,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/288.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  25%|██▌       | 212/834 [01:39<04:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/289.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▌       | 213/834 [01:40<04:52,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/29.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▌       | 214/834 [01:40<04:51,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/290.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▌       | 215/834 [01:40<04:51,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/291.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▌       | 216/834 [01:41<04:50,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/292.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▌       | 217/834 [01:41<04:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/293.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▌       | 218/834 [01:42<04:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/294.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▋       | 219/834 [01:42<04:49,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/295.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▋       | 220/834 [01:43<04:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/296.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  26%|██▋       | 221/834 [01:43<04:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/297.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 222/834 [01:44<04:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/298.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 223/834 [01:44<04:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/299.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 224/834 [01:45<04:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/3.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 225/834 [01:45<04:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/30.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 226/834 [01:46<04:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/300.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 227/834 [01:46<04:45,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/301.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 228/834 [01:47<04:45,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/302.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  27%|██▋       | 229/834 [01:47<04:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/303.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 230/834 [01:48<04:44,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/304.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 231/834 [01:48<04:43,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/305.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 232/834 [01:48<04:43,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/306.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 233/834 [01:49<04:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/307.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 234/834 [01:49<04:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/308.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 235/834 [01:50<04:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/309.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 236/834 [01:50<04:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/31.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 237/834 [01:51<04:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/310.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▊       | 238/834 [01:51<04:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/311.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▊       | 239/834 [01:52<04:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/312.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 240/834 [01:52<04:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/313.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 241/834 [01:53<04:38,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/314.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 242/834 [01:53<04:38,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/315.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 243/834 [01:54<04:38,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/316.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 244/834 [01:54<04:37,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/317.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 245/834 [01:55<04:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/318.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  29%|██▉       | 246/834 [01:55<04:36,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/319.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|██▉       | 247/834 [01:56<04:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/32.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|██▉       | 248/834 [01:56<04:36,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/320.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|██▉       | 249/834 [01:56<04:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/321.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|██▉       | 250/834 [01:57<04:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/322.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|███       | 251/834 [01:57<04:35,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/323.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|███       | 252/834 [01:58<04:34,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/324.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|███       | 253/834 [01:58<04:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/325.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  30%|███       | 254/834 [01:59<04:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/326.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 255/834 [01:59<04:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/327.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 256/834 [02:00<04:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/328.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 257/834 [02:00<04:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/329.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 258/834 [02:01<04:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/33.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 259/834 [02:01<04:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/330.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 260/834 [02:02<04:30,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/331.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███▏      | 261/834 [02:02<04:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/332.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███▏      | 262/834 [02:03<04:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/333.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 263/834 [02:03<04:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/334.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 264/834 [02:04<04:28,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/335.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 265/834 [02:04<04:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/336.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 266/834 [02:04<04:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/337.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 267/834 [02:05<04:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/338.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 268/834 [02:05<04:26,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/339.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 269/834 [02:06<04:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/34.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 270/834 [02:06<04:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/340.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  32%|███▏      | 271/834 [02:07<04:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/341.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 272/834 [02:07<04:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/342.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 273/834 [02:08<04:24,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/343.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 274/834 [02:08<04:23,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/344.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 275/834 [02:09<04:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/345.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 276/834 [02:09<04:22,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/346.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 277/834 [02:10<04:22,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/347.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 278/834 [02:10<04:21,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/348.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  33%|███▎      | 279/834 [02:11<04:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/349.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▎      | 280/834 [02:11<04:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/35.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▎      | 281/834 [02:12<04:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/350.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 282/834 [02:12<04:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/351.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 283/834 [02:12<04:19,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/352.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 284/834 [02:13<04:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/353.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 285/834 [02:13<04:18,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/354.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 286/834 [02:14<04:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/355.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 287/834 [02:14<04:17,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/356.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▍      | 288/834 [02:15<04:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/357.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▍      | 289/834 [02:15<04:16,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/358.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▍      | 290/834 [02:16<04:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/359.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▍      | 291/834 [02:16<04:15,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/36.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▌      | 292/834 [02:17<04:15,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/360.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▌      | 293/834 [02:17<04:14,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/361.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▌      | 294/834 [02:18<04:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/362.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▌      | 295/834 [02:18<04:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/363.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  35%|███▌      | 296/834 [02:19<04:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/364.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▌      | 297/834 [02:19<04:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/365.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▌      | 298/834 [02:20<04:12,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/366.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▌      | 299/834 [02:20<04:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/367.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▌      | 300/834 [02:20<04:11,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/368.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▌      | 301/834 [02:21<04:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/369.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▌      | 302/834 [02:21<04:10,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/37.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▋      | 303/834 [02:22<04:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/370.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  36%|███▋      | 304/834 [02:22<04:09,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/371.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 305/834 [02:23<04:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/372.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 306/834 [02:23<04:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/373.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 307/834 [02:24<04:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/374.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 308/834 [02:24<04:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/375.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 309/834 [02:25<04:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/376.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 310/834 [02:25<04:06,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/377.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 311/834 [02:26<04:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/378.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  37%|███▋      | 312/834 [02:26<04:05,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/379.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 313/834 [02:27<04:05,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/38.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 314/834 [02:27<04:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/380.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 315/834 [02:28<04:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/381.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 316/834 [02:28<04:04,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/382.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 317/834 [02:28<04:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/383.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 318/834 [02:29<04:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/384.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 319/834 [02:29<04:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/385.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 320/834 [02:30<04:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/386.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 321/834 [02:30<04:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/387.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▊      | 322/834 [02:31<04:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/388.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▊      | 323/834 [02:31<03:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/389.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▉      | 324/834 [02:32<03:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/39.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▉      | 325/834 [02:32<03:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/390.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▉      | 326/834 [02:33<03:59,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/391.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▉      | 327/834 [02:33<03:58,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/392.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▉      | 328/834 [02:34<03:58,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/393.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  39%|███▉      | 329/834 [02:34<03:57,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/394.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|███▉      | 330/834 [02:35<03:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/395.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|███▉      | 331/834 [02:35<03:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/396.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|███▉      | 332/834 [02:36<03:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/397.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|███▉      | 333/834 [02:36<03:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/398.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|████      | 334/834 [02:36<03:55,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/399.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|████      | 335/834 [02:37<03:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/4.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|████      | 336/834 [02:37<03:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/40.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  40%|████      | 337/834 [02:38<03:53,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/400.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 338/834 [02:38<03:53,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/401.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 339/834 [02:39<03:53,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/402.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 340/834 [02:39<03:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/403.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 341/834 [02:40<03:52,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/404.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 342/834 [02:40<03:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/405.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 343/834 [02:41<03:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/406.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████      | 344/834 [02:41<03:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/407.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████▏     | 345/834 [02:42<03:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/408.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████▏     | 346/834 [02:42<03:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/409.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 347/834 [02:43<03:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/41.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 348/834 [02:43<03:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/410.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 349/834 [02:44<03:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/411.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 350/834 [02:44<03:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/412.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 351/834 [02:44<03:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/413.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 352/834 [02:45<03:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/414.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 353/834 [02:45<03:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/415.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  42%|████▏     | 354/834 [02:46<03:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/416.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 355/834 [02:46<03:45,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/417.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 356/834 [02:47<03:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/418.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 357/834 [02:47<03:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/419.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 358/834 [02:48<03:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/42.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 359/834 [02:48<03:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/420.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 360/834 [02:49<03:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/421.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 361/834 [02:49<03:42,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/422.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  43%|████▎     | 362/834 [02:50<03:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/423.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▎     | 363/834 [02:50<03:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/424.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▎     | 364/834 [02:51<03:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/425.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 365/834 [02:51<03:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/426.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 366/834 [02:52<03:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/427.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 367/834 [02:52<03:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/428.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 368/834 [02:52<03:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/429.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 369/834 [02:53<03:38,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/43.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 370/834 [02:53<03:38,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/430.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  44%|████▍     | 371/834 [02:54<03:38,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/431.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▍     | 372/834 [02:54<03:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/432.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▍     | 373/834 [02:55<03:37,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/433.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▍     | 374/834 [02:55<03:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/434.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▍     | 375/834 [02:56<03:36,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/435.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▌     | 376/834 [02:56<03:35,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/436.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▌     | 377/834 [02:57<03:35,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/437.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▌     | 378/834 [02:57<03:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/438.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▌     | 379/834 [02:58<03:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/439.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▌     | 380/834 [02:58<03:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/44.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▌     | 381/834 [02:59<03:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/440.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▌     | 382/834 [02:59<03:32,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/441.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▌     | 383/834 [03:00<03:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/442.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▌     | 384/834 [03:00<03:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/443.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▌     | 385/834 [03:00<03:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/444.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▋     | 386/834 [03:01<03:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/445.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  46%|████▋     | 387/834 [03:01<03:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/446.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 388/834 [03:02<03:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/447.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 389/834 [03:02<03:29,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/448.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 390/834 [03:03<03:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/449.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 391/834 [03:03<03:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/45.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 392/834 [03:04<03:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/450.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 393/834 [03:04<03:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/451.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 394/834 [03:05<03:27,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/452.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 395/834 [03:05<03:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/453.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  47%|████▋     | 396/834 [03:06<03:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/454.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 397/834 [03:06<03:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/455.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 398/834 [03:07<03:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/456.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 399/834 [03:07<03:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/457.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 400/834 [03:08<03:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/458.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 401/834 [03:08<03:24,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/459.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 402/834 [03:08<03:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/46.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 403/834 [03:09<03:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/460.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 404/834 [03:09<03:22,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/461.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▊     | 405/834 [03:10<03:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/462.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▊     | 406/834 [03:10<03:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/463.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▉     | 407/834 [03:11<03:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/464.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▉     | 408/834 [03:11<03:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/465.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▉     | 409/834 [03:12<03:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/466.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▉     | 410/834 [03:12<03:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/467.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▉     | 411/834 [03:13<03:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/468.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  49%|████▉     | 412/834 [03:13<03:18,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/469.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|████▉     | 413/834 [03:14<03:18,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/47.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|████▉     | 414/834 [03:14<03:17,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/470.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|████▉     | 415/834 [03:15<03:17,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/471.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|████▉     | 416/834 [03:15<03:16,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/472.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|█████     | 417/834 [03:16<03:16,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/473.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|█████     | 418/834 [03:16<03:16,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/474.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|█████     | 419/834 [03:16<03:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/475.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|█████     | 420/834 [03:17<03:14,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/476.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  50%|█████     | 421/834 [03:17<03:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/477.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████     | 422/834 [03:18<03:13,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/478.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████     | 423/834 [03:18<03:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/479.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████     | 424/834 [03:19<03:12,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/48.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████     | 425/834 [03:19<03:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/480.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████     | 426/834 [03:20<03:12,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/481.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████     | 427/834 [03:20<03:11,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/482.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████▏    | 428/834 [03:21<03:11,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/483.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  51%|█████▏    | 429/834 [03:21<03:10,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/484.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 430/834 [03:22<03:10,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/485.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 431/834 [03:22<03:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/486.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 432/834 [03:23<03:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/487.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 433/834 [03:23<03:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/488.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 434/834 [03:24<03:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/489.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 435/834 [03:24<03:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/49.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 436/834 [03:24<03:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/490.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 437/834 [03:25<03:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/491.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 438/834 [03:25<03:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/492.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 439/834 [03:26<03:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/493.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 440/834 [03:26<03:05,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/494.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 441/834 [03:27<03:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/495.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 442/834 [03:27<03:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/496.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 443/834 [03:28<03:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/497.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 444/834 [03:28<03:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/498.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 445/834 [03:29<03:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/499.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  53%|█████▎    | 446/834 [03:29<03:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/5.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▎    | 447/834 [03:30<03:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/50.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▎    | 448/834 [03:30<03:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/500.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▍    | 449/834 [03:31<03:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/501.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▍    | 450/834 [03:31<03:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/502.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▍    | 451/834 [03:32<02:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/503.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▍    | 452/834 [03:32<02:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/504.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▍    | 453/834 [03:32<02:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/505.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  54%|█████▍    | 454/834 [03:33<02:58,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/506.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▍    | 455/834 [03:33<02:58,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/507.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▍    | 456/834 [03:34<02:57,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/508.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▍    | 457/834 [03:34<02:57,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/509.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▍    | 458/834 [03:35<02:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/51.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▌    | 459/834 [03:35<02:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/510.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▌    | 460/834 [03:36<02:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/511.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▌    | 461/834 [03:36<02:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/512.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▌    | 462/834 [03:37<02:55,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/513.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 463/834 [03:37<02:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/514.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 464/834 [03:38<02:54,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/515.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 465/834 [03:38<02:53,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/516.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 466/834 [03:39<02:53,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/517.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 467/834 [03:39<02:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/518.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 468/834 [03:40<02:52,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/519.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▌    | 469/834 [03:40<02:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/52.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▋    | 470/834 [03:40<02:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/520.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  56%|█████▋    | 471/834 [03:41<02:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/521.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 472/834 [03:41<02:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/522.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 473/834 [03:42<02:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/523.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 474/834 [03:42<02:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/524.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 475/834 [03:43<02:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/525.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 476/834 [03:43<02:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/526.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 477/834 [03:44<02:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/527.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 478/834 [03:44<02:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/528.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  57%|█████▋    | 479/834 [03:45<02:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/529.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 480/834 [03:45<02:46,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/53.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 481/834 [03:46<02:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/530.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 482/834 [03:46<02:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/531.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 483/834 [03:47<02:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/532.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 484/834 [03:47<02:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/533.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 485/834 [03:47<02:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/534.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 486/834 [03:48<02:44,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/535.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  58%|█████▊    | 487/834 [03:48<02:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/536.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▊    | 488/834 [03:49<02:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/537.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▊    | 489/834 [03:49<02:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/538.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 490/834 [03:50<02:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/539.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 491/834 [03:50<02:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/54.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 492/834 [03:51<02:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/540.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 493/834 [03:51<02:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/541.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 494/834 [03:52<02:40,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/542.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 495/834 [03:52<02:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/543.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▉    | 496/834 [03:53<02:38,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/544.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|█████▉    | 497/834 [03:53<02:38,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/545.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|█████▉    | 498/834 [03:54<02:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/546.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|█████▉    | 499/834 [03:54<02:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/547.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|█████▉    | 500/834 [03:55<02:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/548.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|██████    | 501/834 [03:55<02:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/549.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|██████    | 502/834 [03:55<02:36,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/55.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|██████    | 503/834 [03:56<02:35,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/550.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  60%|██████    | 504/834 [03:56<02:35,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/551.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████    | 505/834 [03:57<02:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/552.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████    | 506/834 [03:57<02:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/553.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████    | 507/834 [03:58<02:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/554.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████    | 508/834 [03:58<02:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/555.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████    | 509/834 [03:59<02:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/556.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████    | 510/834 [03:59<02:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/557.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████▏   | 511/834 [04:00<02:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/558.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  61%|██████▏   | 512/834 [04:00<02:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/559.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 513/834 [04:01<02:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/56.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 514/834 [04:01<02:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/560.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 515/834 [04:02<02:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/561.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 516/834 [04:02<02:29,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/562.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 517/834 [04:03<02:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/563.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 518/834 [04:03<02:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/564.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 519/834 [04:03<02:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/565.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 520/834 [04:04<02:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/566.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 521/834 [04:04<02:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/567.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 522/834 [04:05<02:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/568.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 523/834 [04:05<02:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/569.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 524/834 [04:06<02:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/57.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 525/834 [04:06<02:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/570.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 526/834 [04:07<02:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/571.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 527/834 [04:07<02:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/572.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 528/834 [04:08<02:24,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/573.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  63%|██████▎   | 529/834 [04:08<02:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/574.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▎   | 530/834 [04:09<02:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/575.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▎   | 531/834 [04:09<02:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/576.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▍   | 532/834 [04:10<02:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/577.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▍   | 533/834 [04:10<02:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/578.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▍   | 534/834 [04:11<02:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/579.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▍   | 535/834 [04:11<02:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/58.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▍   | 536/834 [04:11<02:20,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/580.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  64%|██████▍   | 537/834 [04:12<02:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/581.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▍   | 538/834 [04:12<02:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/582.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▍   | 539/834 [04:13<02:18,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/583.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▍   | 540/834 [04:13<02:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/584.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▍   | 541/834 [04:14<02:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/585.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▍   | 542/834 [04:14<02:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/586.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▌   | 543/834 [04:15<02:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/587.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▌   | 544/834 [04:15<02:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/588.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▌   | 545/834 [04:16<02:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/589.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  65%|██████▌   | 546/834 [04:16<02:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/59.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 547/834 [04:17<02:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/590.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 548/834 [04:17<02:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/591.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 549/834 [04:18<02:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/592.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 550/834 [04:18<02:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/593.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 551/834 [04:19<02:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/594.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 552/834 [04:19<02:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/595.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▋   | 553/834 [04:19<02:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/596.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▋   | 554/834 [04:20<02:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/597.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 555/834 [04:20<02:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/598.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 556/834 [04:21<02:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/599.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 557/834 [04:21<02:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/6.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 558/834 [04:22<02:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/60.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 559/834 [04:22<02:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/600.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 560/834 [04:23<02:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/601.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 561/834 [04:23<02:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/602.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  67%|██████▋   | 562/834 [04:24<02:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/603.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 563/834 [04:24<02:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/604.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 564/834 [04:25<02:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/605.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 565/834 [04:25<02:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/606.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 566/834 [04:26<02:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/607.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 567/834 [04:26<02:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/608.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 568/834 [04:27<02:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/609.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 569/834 [04:27<02:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/61.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 570/834 [04:27<02:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/610.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  68%|██████▊   | 571/834 [04:28<02:04,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/611.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▊   | 572/834 [04:28<02:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/612.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▊   | 573/834 [04:29<02:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/613.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 574/834 [04:29<02:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/614.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 575/834 [04:30<02:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/615.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 576/834 [04:30<02:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/616.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 577/834 [04:31<02:01,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/617.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 578/834 [04:31<02:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/618.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 579/834 [04:32<01:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/619.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|██████▉   | 580/834 [04:32<01:59,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/62.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|██████▉   | 581/834 [04:33<01:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/620.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|██████▉   | 582/834 [04:33<01:58,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/621.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|██████▉   | 583/834 [04:34<01:57,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/622.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|███████   | 584/834 [04:34<01:57,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/623.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|███████   | 585/834 [04:35<01:57,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/624.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|███████   | 586/834 [04:35<01:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/625.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  70%|███████   | 587/834 [04:35<01:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/626.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 588/834 [04:36<01:55,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/627.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 589/834 [04:36<01:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/628.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 590/834 [04:37<01:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/629.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 591/834 [04:37<01:54,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/63.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 592/834 [04:38<01:54,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/630.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 593/834 [04:38<01:53,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/631.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████   | 594/834 [04:39<01:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/632.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████▏  | 595/834 [04:39<01:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/633.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  71%|███████▏  | 596/834 [04:40<01:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/634.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 597/834 [04:40<01:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/635.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 598/834 [04:41<01:51,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/636.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 599/834 [04:41<01:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/637.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 600/834 [04:42<01:50,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/638.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 601/834 [04:42<01:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/639.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 602/834 [04:43<01:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/64.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 603/834 [04:43<01:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/640.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 604/834 [04:43<01:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/641.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 605/834 [04:44<01:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/642.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 606/834 [04:44<01:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/643.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 607/834 [04:45<01:46,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/644.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 608/834 [04:45<01:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/645.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 609/834 [04:46<01:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/646.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 610/834 [04:46<01:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/647.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 611/834 [04:47<01:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/648.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  73%|███████▎  | 612/834 [04:47<01:44,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/649.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▎  | 613/834 [04:48<01:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/65.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▎  | 614/834 [04:48<01:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/650.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▎  | 615/834 [04:49<01:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/651.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▍  | 616/834 [04:49<01:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/652.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▍  | 617/834 [04:50<01:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/653.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▍  | 618/834 [04:50<01:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/654.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▍  | 619/834 [04:51<01:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/655.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▍  | 620/834 [04:51<01:40,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/656.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  74%|███████▍  | 621/834 [04:51<01:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/657.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▍  | 622/834 [04:52<01:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/658.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▍  | 623/834 [04:52<01:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/659.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▍  | 624/834 [04:53<01:38,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/66.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▍  | 625/834 [04:53<01:38,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/660.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▌  | 626/834 [04:54<01:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/661.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▌  | 627/834 [04:54<01:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/662.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▌  | 628/834 [04:55<01:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/663.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  75%|███████▌  | 629/834 [04:55<01:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/664.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 630/834 [04:56<01:35,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/665.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 631/834 [04:56<01:35,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/666.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 632/834 [04:57<01:35,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/667.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 633/834 [04:57<01:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/668.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 634/834 [04:58<01:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/669.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 635/834 [04:58<01:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/67.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▋  | 636/834 [04:58<01:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/670.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▋  | 637/834 [04:59<01:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/671.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▋  | 638/834 [04:59<01:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/672.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 639/834 [05:00<01:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/673.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 640/834 [05:00<01:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/674.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 641/834 [05:01<01:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/675.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 642/834 [05:01<01:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/676.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 643/834 [05:02<01:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/677.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 644/834 [05:02<01:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/678.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 645/834 [05:03<01:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/679.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  77%|███████▋  | 646/834 [05:03<01:28,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/68.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 647/834 [05:04<01:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/680.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 648/834 [05:04<01:27,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/681.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 649/834 [05:05<01:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/682.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 650/834 [05:05<01:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/683.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 651/834 [05:06<01:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/684.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 652/834 [05:06<01:25,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/685.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 653/834 [05:06<01:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/686.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  78%|███████▊  | 654/834 [05:07<01:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/687.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▊  | 655/834 [05:07<01:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/688.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▊  | 656/834 [05:08<01:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/689.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 657/834 [05:08<01:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/69.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 658/834 [05:09<01:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/690.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 659/834 [05:09<01:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/691.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 660/834 [05:10<01:21,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/692.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 661/834 [05:10<01:21,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/693.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 662/834 [05:11<01:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/694.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 663/834 [05:11<01:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/695.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|███████▉  | 664/834 [05:12<01:20,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/696.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|███████▉  | 665/834 [05:12<01:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/697.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|███████▉  | 666/834 [05:13<01:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/698.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|███████▉  | 667/834 [05:13<01:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/699.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|████████  | 668/834 [05:14<01:18,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/7.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|████████  | 669/834 [05:14<01:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/70.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|████████  | 670/834 [05:14<01:17,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/700.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  80%|████████  | 671/834 [05:15<01:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/701.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████  | 672/834 [05:15<01:16,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/702.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████  | 673/834 [05:16<01:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/703.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████  | 674/834 [05:16<01:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/704.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████  | 675/834 [05:17<01:14,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/705.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████  | 676/834 [05:17<01:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/706.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████  | 677/834 [05:18<01:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/707.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████▏ | 678/834 [05:18<01:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/708.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  81%|████████▏ | 679/834 [05:19<01:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/709.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 680/834 [05:19<01:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/71.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 681/834 [05:20<01:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/710.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 682/834 [05:20<01:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/711.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 683/834 [05:21<01:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/712.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 684/834 [05:21<01:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/713.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 685/834 [05:22<01:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/714.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 686/834 [05:22<01:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/715.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 687/834 [05:22<01:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/716.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  82%|████████▏ | 688/834 [05:23<01:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/717.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 689/834 [05:23<01:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/718.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 690/834 [05:24<01:07,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/719.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 691/834 [05:24<01:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/72.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 692/834 [05:25<01:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/720.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 693/834 [05:25<01:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/721.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 694/834 [05:26<01:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/722.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 695/834 [05:26<01:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/723.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 696/834 [05:27<01:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/724.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▎ | 697/834 [05:27<01:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/725.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▎ | 698/834 [05:28<01:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/726.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▍ | 699/834 [05:28<01:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/727.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▍ | 700/834 [05:29<01:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/728.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▍ | 701/834 [05:29<01:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/729.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▍ | 702/834 [05:30<01:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/73.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▍ | 703/834 [05:30<01:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/730.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  84%|████████▍ | 704/834 [05:30<01:01,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/731.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▍ | 705/834 [05:31<01:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/732.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▍ | 706/834 [05:31<01:00,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/733.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▍ | 707/834 [05:32<00:59,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/734.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▍ | 708/834 [05:32<00:59,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/735.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▌ | 709/834 [05:33<00:58,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/736.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▌ | 710/834 [05:33<00:58,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/737.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▌ | 711/834 [05:34<00:57,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/738.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▌ | 712/834 [05:34<00:57,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/739.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  85%|████████▌ | 713/834 [05:35<00:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/74.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 714/834 [05:35<00:56,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/740.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 715/834 [05:36<00:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/741.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 716/834 [05:36<00:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/742.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 717/834 [05:37<00:55,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/743.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 718/834 [05:37<00:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/744.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 719/834 [05:38<00:54,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/745.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▋ | 720/834 [05:38<00:53,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/746.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▋ | 721/834 [05:38<00:53,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/747.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 722/834 [05:39<00:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/748.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 723/834 [05:39<00:52,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/749.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 724/834 [05:40<00:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/75.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 725/834 [05:40<00:51,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/750.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 726/834 [05:41<00:50,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/751.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 727/834 [05:41<00:50,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/752.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 728/834 [05:42<00:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/753.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  87%|████████▋ | 729/834 [05:42<00:49,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/754.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 730/834 [05:43<00:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/755.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 731/834 [05:43<00:48,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/756.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 732/834 [05:44<00:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/757.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 733/834 [05:44<00:47,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/758.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 734/834 [05:45<00:47,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/759.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 735/834 [05:45<00:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/76.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 736/834 [05:46<00:46,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/760.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 737/834 [05:46<00:45,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/761.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  88%|████████▊ | 738/834 [05:46<00:45,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/762.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▊ | 739/834 [05:47<00:44,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/763.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▊ | 740/834 [05:47<00:44,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/764.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▉ | 741/834 [05:48<00:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/765.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▉ | 742/834 [05:48<00:43,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/766.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▉ | 743/834 [05:49<00:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/767.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▉ | 744/834 [05:49<00:42,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/768.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▉ | 745/834 [05:50<00:41,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/769.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  89%|████████▉ | 746/834 [05:50<00:41,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/77.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|████████▉ | 747/834 [05:51<00:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/770.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|████████▉ | 748/834 [05:51<00:40,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/771.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|████████▉ | 749/834 [05:52<00:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/772.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|████████▉ | 750/834 [05:52<00:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/773.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|█████████ | 751/834 [05:53<00:39,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/774.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|█████████ | 752/834 [05:53<00:38,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/775.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|█████████ | 753/834 [05:54<00:38,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/776.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|█████████ | 754/834 [05:54<00:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/777.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 755/834 [05:54<00:37,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/778.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 756/834 [05:55<00:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/779.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 757/834 [05:55<00:36,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/78.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 758/834 [05:56<00:35,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/780.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 759/834 [05:56<00:35,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/781.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 760/834 [05:57<00:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/782.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████ | 761/834 [05:57<00:34,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/783.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████▏| 762/834 [05:58<00:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/784.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  91%|█████████▏| 763/834 [05:58<00:33,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/785.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 764/834 [05:59<00:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/786.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 765/834 [05:59<00:32,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/787.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 766/834 [06:00<00:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/788.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 767/834 [06:00<00:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/789.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 768/834 [06:01<00:31,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/79.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 769/834 [06:01<00:30,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/790.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 770/834 [06:02<00:30,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/791.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  92%|█████████▏| 771/834 [06:02<00:29,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/792.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 772/834 [06:02<00:29,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/793.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 773/834 [06:03<00:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/794.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 774/834 [06:03<00:28,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/795.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 775/834 [06:04<00:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/796.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 776/834 [06:04<00:27,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/797.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 777/834 [06:05<00:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/798.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 778/834 [06:05<00:26,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/799.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 779/834 [06:06<00:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/8.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▎| 780/834 [06:06<00:25,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/80.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▎| 781/834 [06:07<00:24,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/800.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 782/834 [06:07<00:24,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/801.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 783/834 [06:08<00:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/802.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 784/834 [06:08<00:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/803.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 785/834 [06:09<00:23,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/804.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 786/834 [06:09<00:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/805.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 787/834 [06:10<00:22,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/806.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  94%|█████████▍| 788/834 [06:10<00:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/807.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▍| 789/834 [06:10<00:21,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/808.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▍| 790/834 [06:11<00:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/809.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▍| 791/834 [06:11<00:20,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/81.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▍| 792/834 [06:12<00:19,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/810.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▌| 793/834 [06:12<00:19,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/811.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▌| 794/834 [06:13<00:18,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/812.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▌| 795/834 [06:13<00:18,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/813.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  95%|█████████▌| 796/834 [06:14<00:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/814.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▌| 797/834 [06:14<00:17,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/815.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▌| 798/834 [06:15<00:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/816.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▌| 799/834 [06:15<00:16,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/817.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▌| 800/834 [06:16<00:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/818.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▌| 801/834 [06:16<00:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/819.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▌| 802/834 [06:17<00:15,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/82.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▋| 803/834 [06:17<00:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/820.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  96%|█████████▋| 804/834 [06:17<00:14,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/821.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 805/834 [06:18<00:13,  2.11it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/822.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 806/834 [06:18<00:13,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/823.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 807/834 [06:19<00:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/824.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 808/834 [06:19<00:12,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/825.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 809/834 [06:20<00:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/826.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 810/834 [06:20<00:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/827.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 811/834 [06:21<00:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/828.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 812/834 [06:21<00:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/829.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 813/834 [06:22<00:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/83.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 814/834 [06:22<00:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/830.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 815/834 [06:23<00:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/831.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 816/834 [06:23<00:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/832.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 817/834 [06:24<00:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/833.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 818/834 [06:24<00:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/84.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 819/834 [06:25<00:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/85.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 820/834 [06:25<00:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/86.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  98%|█████████▊| 821/834 [06:25<00:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/87.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▊| 822/834 [06:26<00:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/88.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▊| 823/834 [06:26<00:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/89.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▉| 824/834 [06:27<00:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/9.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▉| 825/834 [06:27<00:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/90.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▉| 826/834 [06:28<00:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/91.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▉| 827/834 [06:28<00:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/92.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▉| 828/834 [06:29<00:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/93.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  99%|█████████▉| 829/834 [06:29<00:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/94.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh: 100%|█████████▉| 830/834 [06:30<00:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/95.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh: 100%|█████████▉| 831/834 [06:30<00:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/96.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh: 100%|█████████▉| 832/834 [06:31<00:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/97.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh: 100%|█████████▉| 833/834 [06:31<00:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/98.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh: 100%|██████████| 834/834 [06:32<00:00,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/99.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   3%|▎         | 1/29 [00:00<00:12,  2.18it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/0.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:   7%|▋         | 2/29 [00:00<00:12,  2.15it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/1.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  10%|█         | 3/29 [00:01<00:12,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/10.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  14%|█▍        | 4/29 [00:01<00:11,  2.14it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/11.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  17%|█▋        | 5/29 [00:02<00:11,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/12.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  21%|██        | 6/29 [00:02<00:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/13.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  24%|██▍       | 7/29 [00:03<00:10,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/14.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  28%|██▊       | 8/29 [00:03<00:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/15.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  31%|███       | 9/29 [00:04<00:09,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/16.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  34%|███▍      | 10/29 [00:04<00:08,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/17.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  38%|███▊      | 11/29 [00:05<00:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/18.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  41%|████▏     | 12/29 [00:05<00:08,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/19.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  45%|████▍     | 13/29 [00:06<00:07,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/2.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  48%|████▊     | 14/29 [00:06<00:07,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/20.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  52%|█████▏    | 15/29 [00:07<00:06,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/21.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  55%|█████▌    | 16/29 [00:07<00:06,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/22.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  59%|█████▊    | 17/29 [00:07<00:05,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/23.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  62%|██████▏   | 18/29 [00:08<00:05,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/24.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  66%|██████▌   | 19/29 [00:08<00:04,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/26.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  69%|██████▉   | 20/29 [00:09<00:04,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/27.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  72%|███████▏  | 21/29 [00:09<00:03,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/28.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  76%|███████▌  | 22/29 [00:10<00:03,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/29.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  79%|███████▉  | 23/29 [00:10<00:02,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/3.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  83%|████████▎ | 24/29 [00:11<00:02,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/4.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  86%|████████▌ | 25/29 [00:11<00:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/5.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  90%|████████▉ | 26/29 [00:12<00:01,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/6.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  93%|█████████▎| 27/29 [00:12<00:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/7.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh:  97%|█████████▋| 28/29 [00:13<00:00,  2.12it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/8.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"Tiền xử lý ảnh: 100%|██████████| 29/29 [00:13<00:00,  2.13it/s]","output_type":"stream"},{"name":"stdout","text":"Lỗi xử lý ảnh /kaggle/input/data-nlp-bai-2/img/img/9.jpg: Kích thước visual_features không đúng: torch.Size([4, 1024])\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'/kaggle/input/data-nlp-bai-2/img/img/0.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/1.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/10.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/11.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/12.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/13.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/14.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/15.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/16.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/17.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/18.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/19.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/2.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/20.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/21.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/22.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/23.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/24.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/26.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/27.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/28.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/29.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/3.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/4.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/5.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/6.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/7.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/8.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]]),\n '/kaggle/input/data-nlp-bai-2/img/img/9.jpg': tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.],\n         [0., 0., 0.,  ..., 0., 0., 0.]])}"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Tạo dataset và dataloader\ntrain_dataset = VQADataset(df_train, tokenizer, cache_dir=\"visual_cache_train\")\ntest_dataset = VQADataset(df_test, tokenizer, cache_dir=\"visual_cache_test\")\ntrain_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n\n# Huấn luyện\nmodel = Vintern1BModel(max_tiles=4).to(device)\noptimizer = AdamW(model.parameters(), lr=1e-5)\nscaler = torch.amp.GradScaler('cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T04:03:02.732441Z","iopub.execute_input":"2025-05-17T04:03:02.732774Z","iopub.status.idle":"2025-05-17T04:03:16.921028Z","shell.execute_reply.started":"2025-05-17T04:03:02.732756Z","shell.execute_reply":"2025-05-17T04:03:16.920427Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94d2bde1d6d94582b7386f140be32c3f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e5cc363edcc5482d96e53554af6b3307"}},"metadata":{}},{"name":"stderr","text":"Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"model.train()\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    optimizer.zero_grad()\n    for i, batch in enumerate(tqdm(train_loader)):\n        visual_tokens = batch['visual_tokens'].to(device)  # [batch_size, num_tiles, 768]\n        question_ids = batch['question_ids'].to(device)\n        question_mask = batch['question_mask'].to(device)\n        answer_ids = batch['answer_ids'].to(device)\n        \n        with torch.amp.autocast('cuda'):\n            outputs = model(visual_tokens, question_ids, question_mask, answer_ids)\n            loss = outputs.loss / ACCUMULATION_STEPS\n        \n        scaler.scale(loss).backward()\n        \n        if (i + 1) % ACCUMULATION_STEPS == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        \n        total_loss += loss.item() * ACCUMULATION_STEPS\n    \n    print(f\"Kỷ nguyên {epoch+1}/{EPOCHS}, Mất mát: {total_loss/len(train_loader)}\")\n\n# Lưu mô hình\ntorch.save(model.state_dict(), \"vintern1b_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T04:03:16.921843Z","iopub.execute_input":"2025-05-17T04:03:16.922066Z","iopub.status.idle":"2025-05-17T04:03:16.998288Z","shell.execute_reply.started":"2025-05-17T04:03:16.922049Z","shell.execute_reply":"2025-05-17T04:03:16.997306Z"}},"outputs":[{"name":"stderr","text":"  0%|          | 0/209 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Không tìm thấy cache cho ảnh /kaggle/input/data-nlp-bai-2/img/img/824.jpg\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2743490909.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mvisual_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'visual_tokens'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, num_tiles, 768]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mquestion_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/1975473513.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mvisual_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_tiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m768\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mvisual_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisual_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [num_tiles, 768]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0midx_qa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'to'"],"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'to'","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"def evaluate_model(model, dataloader, tokenizer):\n    model.eval()\n    predictions, references = [], []\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            visual_tokens = batch['visual_tokens'].to(device)\n            question_ids = batch['question_ids'].to(device)\n            question_mask = batch['question_mask'].to(device)\n            \n            outputs = model(visual_tokens, question_ids, question_mask)\n            pred_ids = torch.argmax(outputs.logits, dim=-1)\n            pred_text = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n            ref_text = tokenizer.batch_decode(batch['answer_ids'], skip_special_tokens=True)\n            \n            predictions.extend(pred_text)\n            references.extend(ref_text)\n    \n    bleu_score = corpus_bleu([[ref.split()] for ref in references], [pred.split() for pred in predictions])\n    rouge_scores = [scorer.score(ref, pred) for ref, pred in zip(references, predictions)]\n    avg_rouge1 = sum([score['rouge1'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n    avg_rougeL = sum([score['rougeL'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n    \n    return bleu_score, avg_rouge1, avg_rougeL\n\nbleu, rouge1, rougeL = evaluate_model(model, test_loader, tokenizer)\nprint(f\"BLEU: {bleu}, ROUGE-1: {rouge1}, ROUGE-L: {rougeL}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T04:03:16.998779Z","iopub.status.idle":"2025-05-17T04:03:16.998991Z","shell.execute_reply.started":"2025-05-17T04:03:16.998890Z","shell.execute_reply":"2025-05-17T04:03:16.998899Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q underthesea\n!pip install -q rouge-score\n!pip install -q nltk\n\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer, ViTModel, ViTImageProcessor\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.optim import AdamW\nimport torch.amp\nimport nltk\nnltk.download('punkt')\nfrom nltk.translate.bleu_score import corpus_bleu\nfrom rouge_score import rouge_scorer\nimport random\nfrom collections import defaultdict\nimport pickle\nimport shutil\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nTRAIN_BATCH_SIZE = 4\nVAL_BATCH_SIZE = 1\nMAX_LEN = 100\nEPOCHS = 2\nACCUMULATION_STEPS = 4\nMAX_TILES = 4\n\ndef split_into_tiles(image, tile_size=448):\n    img_width, img_height = image.size\n    tiles = []\n    for y in range(0, img_height, tile_size):\n        for x in range(0, img_width, tile_size):\n            box = (x, y, min(x + tile_size, img_width), min(y + tile_size, img_height))\n            tile = image.crop(box)\n            if tile.size != (tile_size, tile_size):\n                padded_tile = Image.new('RGB', (tile_size, tile_size), (0, 0, 0))\n                padded_tile.paste(tile, (0, 0))\n                tile = padded_tile\n            tiles.append(tile)\n    return tiles\n\ndef preprocess_images(df, image_processor, vision_encoder, max_tiles=4, cache_dir=\"visual_cache\"):\n    os.makedirs(cache_dir, exist_ok=True)\n    visual_cache = {}\n    grouped = df.groupby('image_path').agg({\n        'question': list,\n        'answer': list,\n        'image_id': 'first',\n        'index': 'first'\n    }).reset_index()\n\n    vision_encoder.eval()\n    with torch.no_grad():\n        for _, row in tqdm(grouped.iterrows(), total=len(grouped), desc=\"Tiền xử lý ảnh\"):\n            image_path = row['image_path']\n            cache_path = os.path.join(cache_dir, f\"{row['image_id']}.pkl\")\n            if os.path.exists(cache_path):\n                continue\n\n            try:\n                image = Image.open(image_path).convert('RGB')\n                tiles = split_into_tiles(image, tile_size=448)[:max_tiles]\n                processed_tiles = [image_processor(tile, return_tensors=\"pt\")['pixel_values'].squeeze(0) for tile in tiles]\n                visual_tokens = torch.stack(processed_tiles).to(device)\n                visual_features = vision_encoder(pixel_values=visual_tokens).last_hidden_state\n                visual_features = visual_features.mean(dim=1)\n                \n                assert visual_features.shape == (max_tiles, 1024), f\"Kích thước visual_features không đúng: {visual_features.shape}\"\n                \n                visual_cache[image_path] = visual_features.cpu()\n                with open(cache_path, 'wb') as f:\n                    pickle.dump(visual_features.cpu(), f)\n            except Exception as e:\n                print(f\"Lỗi xử lý ảnh {image_path}: {e}\")\n                visual_cache[image_path] = torch.zeros((max_tiles, 1024))\n\n    return visual_cache\n\nclass VQADataset(Dataset):\n    def __init__(self, df, tokenizer, cache_dir=\"visual_cache\", max_len=100, max_tiles=4):\n        self.df = df.groupby('image_path').agg({\n            'question': list,\n            'answer': list,\n            'image_id': 'first',\n            'index': 'first'\n        }).reset_index()\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.cache_dir = cache_dir\n        self.max_tiles = max_tiles\n        self.visual_cache = defaultdict(lambda: None)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = row['image_path']\n        questions = row['question']\n        answers = row['answer']\n        image_id = row['image_id']\n\n        if self.visual_cache[image_path] is None:\n            cache_path = os.path.join(self.cache_dir, f\"{image_id}.pkl\")\n            if os.path.exists(cache_path):\n                with open(cache_path, 'rb') as f:\n                    visual_tokens = pickle.load(f)\n                self.visual_cache[image_path] = visual_tokens\n            else:\n                print(f\"Không tìm thấy cache cho ảnh {image_path}\")\n                visual_tokens = torch.zeros((self.max_tiles, 1024))\n\n        visual_tokens = self.visual_cache[image_path].to(device)\n\n        idx_qa = random.randint(0, len(questions) - 1)\n        question = questions[idx_qa]\n        answer = answers[idx_qa]\n\n        question_encoding = self.tokenizer(question, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n        answer_encoding = self.tokenizer(answer, max_length=self.max_len, padding='max_length', truncation=True, return_tensors='pt')\n\n        return {\n            'visual_tokens': visual_tokens,\n            'question_ids': question_encoding['input_ids'].squeeze(),\n            'question_mask': question_encoding['attention_mask'].squeeze(),\n            'answer_ids': answer_encoding['input_ids'].squeeze(),\n            'answer_mask': answer_encoding['attention_mask'].squeeze()\n        }\n\nclass Vintern1BModel(nn.Module):\n    def __init__(self, max_tiles=4):\n        super(Vintern1BModel, self).__init__()\n        self.max_tiles = max_tiles\n        self.mlp_projector = nn.Sequential(\n            nn.Linear(1024, 2048),\n            nn.ReLU(),\n            nn.Linear(2048, 896)  # Đổi từ 4096 thành 896\n        )\n        self.language_model = AutoModel.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\n\n    def forward(self, visual_tokens, question_ids, question_mask, answer_ids=None):\n        batch_size = question_ids.shape[0]\n        if visual_tokens.dim() == 2:\n            visual_tokens = visual_tokens.unsqueeze(0)\n        if visual_tokens.shape[0] != batch_size:\n            visual_tokens = visual_tokens.repeat(batch_size, 1, 1)\n        \n        projected_features = self.mlp_projector(visual_tokens)  # [batch_size, num_tiles, 896]\n        inputs_embeds = self.language_model.get_input_embeddings()(question_ids)  # [batch_size, seq_len, 896]\n        combined_embeds = torch.cat([projected_features.mean(dim=1, keepdim=True), inputs_embeds], dim=1)\n        outputs = self.language_model(inputs_embeds=combined_embeds, attention_mask=question_mask, labels=answer_ids if answer_ids is not None else None)\n        return outputs\n\ndf_train = pd.read_csv(\"/kaggle/input/data-nlp-bai-2/df_train.csv\")\ndf_train = df_train.sort_values(by=[\"image_id\"])\ndf_train = df_train.iloc[:10000]\n\ndf_test = pd.read_csv(\"/kaggle/input/data-nlp-bai-2/df_test.csv\")\ndf_test = df_test.sort_values(by=[\"image_id\"])\ndf_test = df_test.iloc[:100]\n\ntokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-0.5B-Instruct\")\nimage_processor = ViTImageProcessor.from_pretrained(\"OpenGVLab/InternViT-300M-448px\")\nvision_encoder = ViTModel.from_pretrained(\"OpenGVLab/InternViT-300M-448px\").to(device)\n\n# Xóa cache cũ và tiền xử lý lại\nshutil.rmtree(\"visual_cache_train\", ignore_errors=True)\nshutil.rmtree(\"visual_cache_test\", ignore_errors=True)\npreprocess_images(df_train, image_processor, vision_encoder, max_tiles=MAX_TILES, cache_dir=\"visual_cache_train\")\npreprocess_images(df_test, image_processor, vision_encoder, max_tiles=MAX_TILES, cache_dir=\"visual_cache_test\")\n\ntrain_dataset = VQADataset(df_train, tokenizer, cache_dir=\"visual_cache_train\", max_len=MAX_LEN, max_tiles=MAX_TILES)\ntest_dataset = VQADataset(df_test, tokenizer, cache_dir=\"visual_cache_test\", max_len=MAX_LEN, max_tiles=MAX_TILES)\ntrain_loader = DataLoader(train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=VAL_BATCH_SIZE, shuffle=False)\n\nmodel = Vintern1BModel(max_tiles=MAX_TILES).to(device)\noptimizer = AdamW(model.parameters(), lr=1e-5)\nscaler = torch.amp.GradScaler('cuda')\n\nmodel.train()\nfor epoch in range(EPOCHS):\n    total_loss = 0\n    optimizer.zero_grad()\n    for i, batch in enumerate(tqdm(train_loader)):\n        visual_tokens = batch['visual_tokens'].to(device)\n        question_ids = batch['question_ids'].to(device)\n        question_mask = batch['question_mask'].to(device)\n        answer_ids = batch['answer_ids'].to(device)\n        \n        with torch.amp.autocast('cuda'):\n            outputs = model(visual_tokens, question_ids, question_mask, answer_ids)\n            loss = outputs.loss / ACCUMULATION_STEPS\n        \n        scaler.scale(loss).backward()\n        \n        if (i + 1) % ACCUMULATION_STEPS == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n        \n        total_loss += loss.item() * ACCUMULATION_STEPS\n    \n    print(f\"Kỷ nguyên {epoch+1}/{EPOCHS}, Mất mát: {total_loss/len(train_loader)}\")\n\ntorch.save(model.state_dict(), \"vintern1b_model.pth\")\n\ndef evaluate_model(model, dataloader, tokenizer):\n    model.eval()\n    predictions, references = [], []\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n    \n    with torch.no_grad():\n        for batch in tqdm(dataloader):\n            visual_tokens = batch['visual_tokens'].to(device)\n            question_ids = batch['question_ids'].to(device)\n            question_mask = batch['question_mask'].to(device)\n            \n            outputs = model(visual_tokens, question_ids, question_mask)\n            pred_ids = torch.argmax(outputs.logits, dim=-1)\n            pred_text = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n            ref_text = tokenizer.batch_decode(batch['answer_ids'], skip_special_tokens=True)\n            \n            predictions.extend(pred_text)\n            references.extend(ref_text)\n    \n    bleu_score = corpus_bleu([[ref.split()] for ref in references], [pred.split() for pred in predictions])\n    rouge_scores = [scorer.score(ref, pred) for ref, pred in zip(references, predictions)]\n    avg_rouge1 = sum([score['rouge1'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n    avg_rougeL = sum([score['rougeL'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n    \n    return bleu_score, avg_rouge1, avg_rougeL\n\nbleu, rouge1, rougeL = evaluate_model(model, test_loader, tokenizer)\nprint(f\"BLEU: {bleu}, ROUGE-1: {rouge1}, ROUGE-L: {rougeL}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T04:32:25.813903Z","iopub.execute_input":"2025-05-17T04:32:25.814630Z","iopub.status.idle":"2025-05-17T04:40:02.231511Z","shell.execute_reply.started":"2025-05-17T04:32:25.814578Z","shell.execute_reply":"2025-05-17T04:40:02.230065Z"}},"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\nYou are using a model of type intern_vit_6b to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\nSome weights of ViTModel were not initialized from the model checkpoint at OpenGVLab/InternViT-300M-448px and are newly initialized: ['embeddings.cls_token', 'embeddings.patch_embeddings.projection.bias', 'embeddings.patch_embeddings.projection.weight', 'embeddings.position_embeddings', 'encoder.layer.0.attention.attention.key.bias', 'encoder.layer.0.attention.attention.key.weight', 'encoder.layer.0.attention.attention.query.bias', 'encoder.layer.0.attention.attention.query.weight', 'encoder.layer.0.attention.attention.value.bias', 'encoder.layer.0.attention.attention.value.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.attention.key.bias', 'encoder.layer.1.attention.attention.key.weight', 'encoder.layer.1.attention.attention.query.bias', 'encoder.layer.1.attention.attention.query.weight', 'encoder.layer.1.attention.attention.value.bias', 'encoder.layer.1.attention.attention.value.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.attention.key.bias', 'encoder.layer.10.attention.attention.key.weight', 'encoder.layer.10.attention.attention.query.bias', 'encoder.layer.10.attention.attention.query.weight', 'encoder.layer.10.attention.attention.value.bias', 'encoder.layer.10.attention.attention.value.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.attention.key.bias', 'encoder.layer.11.attention.attention.key.weight', 'encoder.layer.11.attention.attention.query.bias', 'encoder.layer.11.attention.attention.query.weight', 'encoder.layer.11.attention.attention.value.bias', 'encoder.layer.11.attention.attention.value.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.attention.attention.key.bias', 'encoder.layer.12.attention.attention.key.weight', 'encoder.layer.12.attention.attention.query.bias', 'encoder.layer.12.attention.attention.query.weight', 'encoder.layer.12.attention.attention.value.bias', 'encoder.layer.12.attention.attention.value.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.layernorm_after.bias', 'encoder.layer.12.layernorm_after.weight', 'encoder.layer.12.layernorm_before.bias', 'encoder.layer.12.layernorm_before.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.attention.attention.key.bias', 'encoder.layer.13.attention.attention.key.weight', 'encoder.layer.13.attention.attention.query.bias', 'encoder.layer.13.attention.attention.query.weight', 'encoder.layer.13.attention.attention.value.bias', 'encoder.layer.13.attention.attention.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.layernorm_after.bias', 'encoder.layer.13.layernorm_after.weight', 'encoder.layer.13.layernorm_before.bias', 'encoder.layer.13.layernorm_before.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.attention.attention.key.bias', 'encoder.layer.14.attention.attention.key.weight', 'encoder.layer.14.attention.attention.query.bias', 'encoder.layer.14.attention.attention.query.weight', 'encoder.layer.14.attention.attention.value.bias', 'encoder.layer.14.attention.attention.value.weight', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.layernorm_after.bias', 'encoder.layer.14.layernorm_after.weight', 'encoder.layer.14.layernorm_before.bias', 'encoder.layer.14.layernorm_before.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.attention.attention.key.bias', 'encoder.layer.15.attention.attention.key.weight', 'encoder.layer.15.attention.attention.query.bias', 'encoder.layer.15.attention.attention.query.weight', 'encoder.layer.15.attention.attention.value.bias', 'encoder.layer.15.attention.attention.value.weight', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.layernorm_after.bias', 'encoder.layer.15.layernorm_after.weight', 'encoder.layer.15.layernorm_before.bias', 'encoder.layer.15.layernorm_before.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.attention.attention.key.bias', 'encoder.layer.16.attention.attention.key.weight', 'encoder.layer.16.attention.attention.query.bias', 'encoder.layer.16.attention.attention.query.weight', 'encoder.layer.16.attention.attention.value.bias', 'encoder.layer.16.attention.attention.value.weight', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.layernorm_after.bias', 'encoder.layer.16.layernorm_after.weight', 'encoder.layer.16.layernorm_before.bias', 'encoder.layer.16.layernorm_before.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.attention.attention.key.bias', 'encoder.layer.17.attention.attention.key.weight', 'encoder.layer.17.attention.attention.query.bias', 'encoder.layer.17.attention.attention.query.weight', 'encoder.layer.17.attention.attention.value.bias', 'encoder.layer.17.attention.attention.value.weight', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.layernorm_after.bias', 'encoder.layer.17.layernorm_after.weight', 'encoder.layer.17.layernorm_before.bias', 'encoder.layer.17.layernorm_before.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.attention.attention.key.bias', 'encoder.layer.18.attention.attention.key.weight', 'encoder.layer.18.attention.attention.query.bias', 'encoder.layer.18.attention.attention.query.weight', 'encoder.layer.18.attention.attention.value.bias', 'encoder.layer.18.attention.attention.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.layernorm_after.bias', 'encoder.layer.18.layernorm_after.weight', 'encoder.layer.18.layernorm_before.bias', 'encoder.layer.18.layernorm_before.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.attention.attention.key.bias', 'encoder.layer.19.attention.attention.key.weight', 'encoder.layer.19.attention.attention.query.bias', 'encoder.layer.19.attention.attention.query.weight', 'encoder.layer.19.attention.attention.value.bias', 'encoder.layer.19.attention.attention.value.weight', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.layernorm_after.bias', 'encoder.layer.19.layernorm_after.weight', 'encoder.layer.19.layernorm_before.bias', 'encoder.layer.19.layernorm_before.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.attention.attention.key.bias', 'encoder.layer.2.attention.attention.key.weight', 'encoder.layer.2.attention.attention.query.bias', 'encoder.layer.2.attention.attention.query.weight', 'encoder.layer.2.attention.attention.value.bias', 'encoder.layer.2.attention.attention.value.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.2.layernorm_after.weight', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.attention.attention.key.bias', 'encoder.layer.20.attention.attention.key.weight', 'encoder.layer.20.attention.attention.query.bias', 'encoder.layer.20.attention.attention.query.weight', 'encoder.layer.20.attention.attention.value.bias', 'encoder.layer.20.attention.attention.value.weight', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.layernorm_after.bias', 'encoder.layer.20.layernorm_after.weight', 'encoder.layer.20.layernorm_before.bias', 'encoder.layer.20.layernorm_before.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.attention.attention.key.bias', 'encoder.layer.21.attention.attention.key.weight', 'encoder.layer.21.attention.attention.query.bias', 'encoder.layer.21.attention.attention.query.weight', 'encoder.layer.21.attention.attention.value.bias', 'encoder.layer.21.attention.attention.value.weight', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.layernorm_after.bias', 'encoder.layer.21.layernorm_after.weight', 'encoder.layer.21.layernorm_before.bias', 'encoder.layer.21.layernorm_before.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.attention.attention.key.bias', 'encoder.layer.22.attention.attention.key.weight', 'encoder.layer.22.attention.attention.query.bias', 'encoder.layer.22.attention.attention.query.weight', 'encoder.layer.22.attention.attention.value.bias', 'encoder.layer.22.attention.attention.value.weight', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.layernorm_after.bias', 'encoder.layer.22.layernorm_after.weight', 'encoder.layer.22.layernorm_before.bias', 'encoder.layer.22.layernorm_before.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.attention.attention.key.bias', 'encoder.layer.23.attention.attention.key.weight', 'encoder.layer.23.attention.attention.query.bias', 'encoder.layer.23.attention.attention.query.weight', 'encoder.layer.23.attention.attention.value.bias', 'encoder.layer.23.attention.attention.value.weight', 'encoder.layer.23.attention.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.layernorm_after.bias', 'encoder.layer.23.layernorm_after.weight', 'encoder.layer.23.layernorm_before.bias', 'encoder.layer.23.layernorm_before.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.attention.attention.key.bias', 'encoder.layer.3.attention.attention.key.weight', 'encoder.layer.3.attention.attention.query.bias', 'encoder.layer.3.attention.attention.query.weight', 'encoder.layer.3.attention.attention.value.bias', 'encoder.layer.3.attention.attention.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.attention.key.bias', 'encoder.layer.4.attention.attention.key.weight', 'encoder.layer.4.attention.attention.query.bias', 'encoder.layer.4.attention.attention.query.weight', 'encoder.layer.4.attention.attention.value.bias', 'encoder.layer.4.attention.attention.value.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.attention.key.bias', 'encoder.layer.5.attention.attention.key.weight', 'encoder.layer.5.attention.attention.query.bias', 'encoder.layer.5.attention.attention.query.weight', 'encoder.layer.5.attention.attention.value.bias', 'encoder.layer.5.attention.attention.value.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.attention.key.bias', 'encoder.layer.6.attention.attention.key.weight', 'encoder.layer.6.attention.attention.query.bias', 'encoder.layer.6.attention.attention.query.weight', 'encoder.layer.6.attention.attention.value.bias', 'encoder.layer.6.attention.attention.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.attention.key.bias', 'encoder.layer.7.attention.attention.key.weight', 'encoder.layer.7.attention.attention.query.bias', 'encoder.layer.7.attention.attention.query.weight', 'encoder.layer.7.attention.attention.value.bias', 'encoder.layer.7.attention.attention.value.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.7.layernorm_before.bias', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.attention.key.bias', 'encoder.layer.8.attention.attention.key.weight', 'encoder.layer.8.attention.attention.query.bias', 'encoder.layer.8.attention.attention.query.weight', 'encoder.layer.8.attention.attention.value.bias', 'encoder.layer.8.attention.attention.value.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.8.layernorm_after.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.attention.key.bias', 'encoder.layer.9.attention.attention.key.weight', 'encoder.layer.9.attention.attention.query.bias', 'encoder.layer.9.attention.attention.query.weight', 'encoder.layer.9.attention.attention.value.bias', 'encoder.layer.9.attention.attention.value.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'layernorm.bias', 'layernorm.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nTiền xử lý ảnh: 100%|██████████| 834/834 [07:02<00:00,  1.97it/s]\nTiền xử lý ảnh: 100%|██████████| 29/29 [00:14<00:00,  1.97it/s]\n  0%|          | 0/209 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2057372760.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvisual_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mACCUMULATION_STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_35/2057372760.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, visual_tokens, question_ids, question_mask, answer_ids)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion_ids\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [batch_size, seq_len, 896]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mcombined_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprojected_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcombined_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquestion_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manswer_ids\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0manswer_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_requested_to_return_tuple\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_configured_to_return_tuple\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_top_level_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 )\n\u001b[1;32m    548\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                 layer_outputs = decoder_layer(\n\u001b[0m\u001b[1;32m    550\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         hidden_states, self_attn_weights = self.self_attn(\n\u001b[0m\u001b[1;32m    263\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/qwen2/modeling_qwen2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_value, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mattention_interface\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mALL_ATTENTION_FUNCTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attn_implementation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         attn_output, attn_weights = attention_interface(\n\u001b[0m\u001b[1;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mquery_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/integrations/sdpa_attention.py\u001b[0m in \u001b[0;36msdpa_attention_forward\u001b[0;34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mis_causal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     attn_output = torch.nn.functional.scaled_dot_product_attention(\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (101) must match the existing size (100) at non-singleton dimension 3.  Target sizes: [4, 14, 101, 101].  Tensor sizes: [4, 1, 101, 100]"],"ename":"RuntimeError","evalue":"The expanded size of the tensor (101) must match the existing size (100) at non-singleton dimension 3.  Target sizes: [4, 14, 101, 101].  Tensor sizes: [4, 1, 101, 100]","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}